{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guided Tour of Ray Core: Ray's Multiprocessing Pool\n",
    "\n",
    "¬© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "üìñ [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "‚û° [Next notebook](./ex_06_ray_api_calls.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_04_remote_classes_revisited.ipynb) <br>\n",
    "\n",
    "### Overview\n",
    "\n",
    "[*Distributed multiprocessing.Pool*](https://docs.ray.io/en/latest/multiprocessing.html) makes it easy to scale existing Python applications that use [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html) by leveraging *Ray Actors*. Ray supports running distributed python programs with the **multiprocessing.Pool** API using Ray Actors, each running on a [workder node's](https://docs.ray.io/en/latest/ray-core/actors.html#faq-actors-workers-and-resources) dedicated process, instead of local processes on a single host. This makes it easy to scale existing applications that use regular `multiprocessing.Pool` from a single node to a cluster.\n",
    "\n",
    "<img src=\"images/dist_multi_pool.png\" width=\"80%\" height=\"55%\">\n",
    "\n",
    "### Learning objectives\n",
    "In this this tutorial, you will learn how to use:\n",
    "\n",
    " * Ray's replacement for Python's normal `Multiprocessing.pool` library "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a go ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import ray\n",
    "from ray.util.multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing Pool example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a simple Python function with a slight delay added (to make it behave like a more complex calculation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be some complicated and compute intensive task\n",
    "def func(x):\n",
    "    time.sleep(1.5)\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute prime numbers\n",
    "A slightly more compute intensvie function to compute prime numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute some prime numbers between a range  2-->N\n",
    "def is_prime(n):\n",
    "    for divisor in range(2, int(n ** 0.5) + 1):\n",
    "        if n % divisor == 0:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0rc1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.13', ray_version='2.0.0rc1', ray_commit='321d8717f73995153d4f9abe98678160831090e1', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-08-18_15-06-25_979144_90596/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-18_15-06-25_979144_90596/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-08-18_15-06-25_979144_90596', 'metrics_export_port': 63914, 'gcs_address': '127.0.0.1:63323', 'address': '127.0.0.1:63323', 'dashboard_agent_listen_port': 52365, 'node_id': '1df82d583bda5327e799a5063ba9a390bb33479c510e2f70f543b788'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ray.init(logging_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a *Pool* of Actors and distribute its tasks across a cluster (or across the available cores on a laptop). \n",
    "\n",
    "Let's use Ray's drop-in replacement for [multiprocessing pool](https://docs.ray.io/en/latest/multiprocessing.html) uses Ray Actors to distribute the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "100\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "# Create a Pool of Actors\n",
    "pool = Pool() # by default it will create pool == number of cores on the machine\n",
    "\n",
    "for result in pool.map(func, range(12)):\n",
    "    time.sleep(2)      # sleep for you to check the dashboard; you should see Actors == num of cpus\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The distributed version has the trade-off of initial increased overhead, albeit now it can scale-out horizontally across a cluster. The benefits are more pronounced with a more computationally expensive calculation. In other words, its value is amortized over time with compute-intensive complex operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 2000000 \n",
    "lst = list(range(num))\n",
    "results = []\n",
    "\n",
    "# Create a Pool of five actors\n",
    "pool = Pool(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of primes in 2000000 are 148935\n",
      "CPU times: user 3.87 s, sys: 140 ms, total: 4.01 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for result in pool.map(is_prime, lst):\n",
    "    results.append(result)\n",
    "print(f\"Total number of primes in {num} are {sum(results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a compute intensive class that does some matrix\n",
    "computation. Consider this to be a compute intenstive task\n",
    "doing massive tensor transformation or computation.\n",
    "\n",
    "**NOTE**: This will be your excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(n):\n",
    "    # Simulate a long intensive task\n",
    "    # TODO for your excercise\n",
    "    \n",
    "    # May be consider a compute-intensive matrix computation \n",
    "    # and return results\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Ray remote task that launches `task()` across a pool of Actors on the cluster. It creates\n",
    "a pool of `Ray Actors`, each scheduled on a cluster node's worker process. \n",
    "\n",
    "On a single node or localhost it will be an Actor per CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A long running task doing the work: collecting data, updating the database, transforming data, etc\n",
    "# Create an Actor pool of num_pool workers nodes\n",
    "@ray.remote\n",
    "def launch_long_running_tasks(num_pool):\n",
    "    pool = Pool(num_pool) # num_pool of Actors\n",
    "    results = []\n",
    "    # Iterate over 50 times in batches of 10\n",
    "    # TODO, replace func with task() here for the exercise\n",
    "    for result in pool.map(func, range(1, 51, 10)):\n",
    "        results.append(result)\n",
    "        \n",
    "    # Done so terminate pool\n",
    "    pool.terminate()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Actor like supervisor that launches all these remote tasks\n",
    "\n",
    "Remember we have seen this desing pattern: Supervisor and workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class LaunchDistributedTasks:\n",
    "    def __init__(self, limit=5):\n",
    "        self._limit = limit\n",
    "\n",
    "    def launch(self):\n",
    "        # launch the remote task\n",
    "        return launch_long_running_tasks.remote(self._limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our supervisor actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher = LaunchDistributedTasks.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " list of results :[1, 121, 441, 961, 1681]\n",
      " Total results: 5\n"
     ]
    }
   ],
   "source": [
    "# The inner get() returns the list of ObjectRef or \n",
    "# The second get() fetch the values of each ObjectRef\n",
    "#\n",
    "values = ray.get(ray.get(launcher.launch.remote()))\n",
    "print(f\" list of results :{values}\")\n",
    "print(f\" Total results: {len(values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercises\n",
    "\n",
    "1. Can you convert `task()` into a compute-intensive function?\n",
    "2. Use `task()` in `pool.map(task,....)`\n",
    "3. (**Optional**)  Explore the CPU bound tasks using different Python and Ray strategies for distribute computing in this [notebook](extra/mp_all_nb.ipynb) in the `extra` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "Read and work through the these references to see the power of Ray multiprocessing over the cluster with multiple nodes, multiple cores. It shines with compute intensive tasks, such as image processing and numerical computations. \n",
    "1. [10x Faster Parallel Python Without Python Multiprocessing](https://towardsdatascience.com/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1)\n",
    "\n",
    "<img src =\"https://miro.medium.com/max/1200/1*BXnuxGm7vYUh1pfwbTy-XA.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step\n",
    "\n",
    "Let's take a tour of the [Ray APIs and Tips & Tricks](ex_06_ray_api_calls.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìñ [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "‚û° [Next notebook](./ex_06_ray_api_calls.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_04_remote_classes_revisited.ipynb) <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
