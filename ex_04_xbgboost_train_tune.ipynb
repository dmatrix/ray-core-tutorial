{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f8ad5d-4621-4fa2-887b-9696008d9b42",
   "metadata": {},
   "source": [
    "# Distributed HPO with Ray Tune and XGBoost-Ray\n",
    "\n",
    "This demo introduces **Ray tune's** key concepts using a a classification example. This example is derived from [Hyperparametere Tuning with Ray Tune and XGBoost-Ray](https://github.com/ray-project/xgboost_ray#hyperparameter-tuning). Basically, there are three basic steps or Ray Tune pattern for you as a newcomer to get started with using Ray Tune.\n",
    "\n",
    " 1. Setup your config space and define your trainable and objective function\n",
    " 2. Use tune to execute your training, supplying the appropriate arguments including: search space, [search algorithms](https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#blendsearch) or [trial schedulers](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-schedulers)\n",
    " 3. Examine analyse the results\n",
    " \n",
    " <img src=\"https://docs.ray.io/en/latest/_images/tune-workflow.png\" height=\"50%\" width=\"60%\">\n",
    "\n",
    "\n",
    "See also the [Hyperparameter Tuning References](References-Hyperparameter-Tuning.ipynb) notebook and the [Tune documentation](http://tune.io), in particular, the [API reference](https://docs.ray.io/en/latest/tune/api_docs/overview.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b8885d-b698-419f-b43f-d91a073052c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "CONNECT_TO_ANYSCALE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dd77f0-672e-461c-ad45-ff9b5079c819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mAuthenticating\u001b[0m\n",
      "Loaded Anyscale authentication token from ANYSCALE_CLI_TOKEN.\n",
      "\n",
      "\u001b[1m\u001b[36mOutput\u001b[0m\n",
      "\u001b[22m\u001b[33m(anyscale +2.9s)\u001b[0m WARNING: No working_dir specified! Files will only be uploaded to the cluster if a working_dir is provided or a project is detected. In the future, files will only be uploaded if working_dir is provided. To ensure files continue being imported going forward, set the working_dir in your runtime environment. See https://docs.ray.io/en/latest/handling-dependencies.html#runtime-environments.\n",
      "\u001b[1m\u001b[36m(anyscale +3.4s)\u001b[0m .anyscale.yaml found in project_dir. Directory is attached to a project.\n",
      "\u001b[1m\u001b[36m(anyscale +4.4s)\u001b[0m Using project (name: prj-weekly-demo, project_dir: /Users/jules/git-repos/ray-core-tutorial, id: prj_5rvR1w2ciyUs9RM27FeZ6FVB).\n",
      "\u001b[1m\u001b[36m(anyscale +7.6s)\u001b[0m cluster jsd-weekly-demo is currently running, the cluster will not be restarted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 16:17:49,561\tINFO packaging.py:352 -- Creating a file package for local directory '/Users/jules/git-repos/ray-core-tutorial'.\n",
      "2022-01-05 16:17:49,585\tINFO packaging.py:221 -- Pushing file package 'gcs://_ray_pkg_bd137497e8c59fde.zip' (1.94MiB) to Ray cluster...\n",
      "2022-01-05 16:17:52,156\tINFO packaging.py:224 -- Successfully pushed file package 'gcs://_ray_pkg_bd137497e8c59fde.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m(anyscale +34.6s)\u001b[0m Connected to jsd-weekly-demo, see: https://console.anyscale.com/projects/prj_5rvR1w2ciyUs9RM27FeZ6FVB/clusters/ses_GKnU1MGrXqZNmAkicHxSKU9G\n",
      "\u001b[1m\u001b[36m(anyscale +34.6s)\u001b[0m URL for head node of cluster: https://session-gknu1mgrxqznmakichxsku9g.i.anyscaleuserdata.com\n"
     ]
    }
   ],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "    if CONNECT_TO_ANYSCALE:\n",
    "        ray.init(\"anyscale://jsd-weekly-demo\")\n",
    "    else:\n",
    "        ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7515b4-c4eb-4068-a908-f53769ef35ab",
   "metadata": {},
   "source": [
    "## Step 1: Define a 'Trainable' training function to use with Ray Tune `ray.tune(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b632024-1e88-4972-8687-46d58a5910f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ACTORS = 4           # degree of parallel trials; each actor will have a separate trial\n",
    "NUM_OF_CPUS_PER_ACTOR = 1   # number of CPUs per actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa72d37-e6d3-4cae-ba41-4556d6dc15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_params = RayParams(num_actors=NUM_OF_ACTORS, cpus_per_actor=NUM_OF_CPUS_PER_ACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ab5961-daac-4986-a9d3-5c224990c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func_model(config:dict, checkpoint_dir=None):\n",
    "    # create the dataset\n",
    "    train_X, train_y = load_breast_cancer(return_X_y=True)\n",
    "    # Convert to RayDMatrix data structure\n",
    "    train_set = RayDMatrix(train_X, train_y)\n",
    "\n",
    "    # Empty dictionary for the evaluation results reported back\n",
    "    # to tune\n",
    "    evals_result = {}\n",
    "\n",
    "    # Train the model with XGBoost train\n",
    "    bst = train(\n",
    "        params=config,                       # our hyperparameter search space\n",
    "        dtrain=train_set,                    # our RayDMatrix data structure\n",
    "        evals_result=evals_result,           # place holder for results\n",
    "        evals=[(train_set, \"train\")],\n",
    "        verbose_eval=False,\n",
    "        ray_params=ray_params)                # distributed parameters configs for Ray Tune\n",
    "\n",
    "    bst.save_model(\"model.xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f68cc5-6999-4bef-99e8-f68c6a5052c5",
   "metadata": {},
   "source": [
    "## Step 2: Define a hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a35e0c3-f0e5-4efd-a7a8-ffdf28dc5216",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Specify the hyperparameter search space\n",
    "config = {\n",
    "    \"tree_method\": \"approx\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    \"eta\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"subsample\": tune.uniform(0.5, 1.0),\n",
    "    \"max_depth\": tune.randint(1, 9)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee450f-0eee-4fa1-ad81-f39a3247ef12",
   "metadata": {},
   "source": [
    "## Step 3: Run Ray tune main trainer and examine the results\n",
    "\n",
    "Ray Tune will launch distributed HPO, using four remote actors, each with its own instance of the trainable func\n",
    "\n",
    "<img src=\"images/ray_tune_dist_hpo.png\" height=\"50%\" width=\"60%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36a1548-90e7-4699-98d1-7e88cbab154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current time: 2022-01-05 16:18:05 (running for 00:00:00.12)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Memory usage on this node: 3.1/62.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Resources requested: 0/80 CPUs, 0/0 GPUs, 0.0/216.2 GiB heap, 0.0/92.17 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result logdir: /home/ray/ray_results/train_func_model_2022-01-05_16-18-04\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Number of trials: 4/4 (4 PENDING)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+----------+-------+-------------+-------------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | Trial name                   | status   | loc   |         eta |   max_depth |   subsample |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m |------------------------------+----------+-------+-------------+-------------+-------------|\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00000 | PENDING  |       | 0.000913403 |           7 |    0.872278 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00001 | PENDING  |       | 0.0319993   |           8 |    0.720519 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00002 | PENDING  |       | 0.0264598   |           1 |    0.950598 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00003 | PENDING  |       | 0.00169914  |           7 |    0.911883 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+----------+-------+-------------+-------------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=17733)\u001b[0m 2022-01-05 16:18:07,547\tINFO main.py:926 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1626, ip=172.31.74.136)\u001b[0m 2022-01-05 16:18:07,612\tINFO main.py:926 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1655, ip=172.31.85.248)\u001b[0m 2022-01-05 16:18:07,644\tINFO main.py:926 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1358, ip=172.31.89.96)\u001b[0m 2022-01-05 16:18:09,628\tINFO main.py:926 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=17733)\u001b[0m 2022-01-05 16:18:09,665\tINFO main.py:971 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=17797)\u001b[0m [16:18:09] task [xgboost.ray]:140110013325808 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=17794)\u001b[0m [16:18:09] task [xgboost.ray]:140011386044912 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=17795)\u001b[0m [16:18:09] task [xgboost.ray]:139615254065648 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=17796)\u001b[0m [16:18:09] task [xgboost.ray]:139897901445616 got new rank 2\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1655, ip=172.31.85.248)\u001b[0m 2022-01-05 16:18:09,762\tINFO main.py:971 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1626, ip=172.31.74.136)\u001b[0m 2022-01-05 16:18:09,730\tINFO main.py:971 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1661, ip=172.31.74.136)\u001b[0m [16:18:09] task [xgboost.ray]:140643584447104 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1660, ip=172.31.74.136)\u001b[0m [16:18:09] task [xgboost.ray]:140422720303648 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1658, ip=172.31.74.136)\u001b[0m [16:18:09] task [xgboost.ray]:140502832272000 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1659, ip=172.31.74.136)\u001b[0m [16:18:09] task [xgboost.ray]:139661361963648 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1688, ip=172.31.85.248)\u001b[0m [16:18:09] task [xgboost.ray]:139905081483856 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1689, ip=172.31.85.248)\u001b[0m [16:18:09] task [xgboost.ray]:140356251910736 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1687, ip=172.31.85.248)\u001b[0m [16:18:09] task [xgboost.ray]:140017273598544 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1690, ip=172.31.85.248)\u001b[0m [16:18:09] task [xgboost.ray]:140345761038928 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00000:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: f60d9120bf7a414aa308e7a475ac1290\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-57-130\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.57.130\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 17733\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 3.1184630393981934\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 3.1184630393981934\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 3.1184630393981934\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428290\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.029877\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.69234\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00000\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current time: 2022-01-05 16:18:10 (running for 00:00:05.46)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Memory usage on this node: 3.7/62.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Resources requested: 20.0/80 CPUs, 0/0 GPUs, 0.0/216.2 GiB heap, 0.0/92.17 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current best trial: 1d96d_00000 with train-error=0.029877 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0009134032210727258, 'subsample': 0.8722780805626716, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result logdir: /home/ray/ray_results/train_func_model_2022-01-05_16-18-04\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+----------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | Trial name                   | status   | loc                 |         eta |   max_depth |   subsample |   iter |   total time (s) |   train-logloss |   train-error |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m |------------------------------+----------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------|\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00000 | RUNNING  | 172.31.57.130:17733 | 0.000913403 |           7 |    0.872278 |      1 |          3.11846 |         0.69234 |      0.029877 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00001 | RUNNING  | 172.31.74.136:1626  | 0.0319993   |           8 |    0.720519 |        |                  |                 |               |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00002 | RUNNING  | 172.31.89.96:1358   | 0.0264598   |           1 |    0.950598 |        |                  |                 |               |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00003 | RUNNING  | 172.31.85.248:1655  | 0.00169914  |           7 |    0.911883 |        |                  |                 |               |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+----------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00000:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: f60d9120bf7a414aa308e7a475ac1290\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_tag: 0_eta=0.0009134,max_depth=7,subsample=0.87228\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-57-130\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.57.130\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 17733\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 3.165012836456299\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 0.0042231082916259766\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 3.165012836456299\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428290\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.012302\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.685199\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00000\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00001:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 58b79055036a4e79be3eb96d8352c38b\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-74-136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.74.136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1626\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 3.2042365074157715\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 3.2042365074157715\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 3.2042365074157715\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428290\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.035149\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.665561\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00001\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:10,791\tWARN commands.py:269 -- Loaded cached provider configuration\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:10,791\tWARN commands.py:270 -- If you experience issues with the cloud provider, try re-running the command with --no-config-cache.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=17733)\u001b[0m 2022-01-05 16:18:10,606\tINFO main.py:1450 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.11 seconds (0.94 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \u001b[1m\u001b[36mAuthenticating\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1358, ip=172.31.89.96)\u001b[0m 2022-01-05 16:18:11,747\tINFO main.py:971 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1480, ip=172.31.89.96)\u001b[0m [16:18:11] task [xgboost.ray]:139885649756704 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1481, ip=172.31.89.96)\u001b[0m [16:18:11] task [xgboost.ray]:139810916438560 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1479, ip=172.31.89.96)\u001b[0m [16:18:11] task [xgboost.ray]:140519621620256 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1482, ip=172.31.89.96)\u001b[0m [16:18:11] task [xgboost.ray]:139724400329248 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Loaded Anyscale authentication token from variable.\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:22,389\tINFO command_runner.py:357 -- Fetched IP: 172.31.74.136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:22,389\tINFO log_timer.py:25 -- NodeUpdater: ins_bFQmuSwNVtjwmteVTfsQE6Qu: Got IP  [LogTimer=363ms]\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current time: 2022-01-05 16:18:23 (running for 00:00:18.08)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Memory usage on this node: 3.2/62.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Resources requested: 15.0/80 CPUs, 0/0 GPUs, 0.0/216.2 GiB heap, 0.0/92.17 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current best trial: 1d96d_00000 with train-error=0.012302 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0009134032210727258, 'subsample': 0.8722780805626716, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result logdir: /home/ray/ray_results/train_func_model_2022-01-05_16-18-04\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Number of trials: 4/4 (3 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | Trial name                   | status     | loc                 |         eta |   max_depth |   subsample |   iter |   total time (s) |   train-logloss |   train-error |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m |------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------|\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00001 | RUNNING    | 172.31.74.136:1626  | 0.0319993   |           8 |    0.720519 |      1 |          3.20424 |        0.665561 |      0.035149 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00002 | RUNNING    | 172.31.89.96:1358   | 0.0264598   |           1 |    0.950598 |        |                  |                 |               |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00003 | RUNNING    | 172.31.85.248:1655  | 0.00169914  |           7 |    0.911883 |        |                  |                 |               |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00000 | TERMINATED | 172.31.57.130:17733 | 0.000913403 |           7 |    0.872278 |     10 |          3.16501 |        0.685199 |      0.012302 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00001:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-23\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 58b79055036a4e79be3eb96d8352c38b\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-74-136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.74.136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1626\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 15.666953563690186\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 12.462717056274414\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 15.666953563690186\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428303\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.024605\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.640263\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00001\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00003:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 7fd2c0791a04419fa78e5ea26dc8b0ef\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-85-248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.85.248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1655\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 3.2432734966278076\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 3.2432734966278076\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 3.2432734966278076\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428290\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.02812\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.691643\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00003\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:28,522\tINFO command_runner.py:357 -- Fetched IP: 172.31.85.248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:28,522\tINFO log_timer.py:25 -- NodeUpdater: ins_TxkmDW4QVsmT8p56q7sdpMK3: Got IP  [LogTimer=330ms]\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current time: 2022-01-05 16:18:29 (running for 00:00:24.19)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Memory usage on this node: 3.2/62.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Resources requested: 15.0/80 CPUs, 0/0 GPUs, 0.0/216.2 GiB heap, 0.0/92.17 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current best trial: 1d96d_00000 with train-error=0.012302 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0009134032210727258, 'subsample': 0.8722780805626716, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result logdir: /home/ray/ray_results/train_func_model_2022-01-05_16-18-04\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Number of trials: 4/4 (3 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | Trial name                   | status     | loc                 |         eta |   max_depth |   subsample |   iter |   total time (s) |   train-logloss |   train-error |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m |------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------|\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00001 | RUNNING    | 172.31.74.136:1626  | 0.0319993   |           8 |    0.720519 |      2 |         15.667   |        0.640263 |      0.024605 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00002 | RUNNING    | 172.31.89.96:1358   | 0.0264598   |           1 |    0.950598 |        |                  |                 |               |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00003 | RUNNING    | 172.31.85.248:1655  | 0.00169914  |           7 |    0.911883 |      1 |          3.24327 |        0.691643 |      0.02812  |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00000 | TERMINATED | 172.31.57.130:17733 | 0.000913403 |           7 |    0.872278 |     10 |          3.16501 |        0.685199 |      0.012302 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00001:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-23\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 58b79055036a4e79be3eb96d8352c38b\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-74-136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 3\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.74.136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1626\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 15.678977727890015\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 0.012024164199829102\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 15.678977727890015\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428303\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.019332\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.615177\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00001\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00003:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-29\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 7fd2c0791a04419fa78e5ea26dc8b0ef\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-85-248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.85.248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1655\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 21.753560543060303\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 18.510287046432495\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 21.753560543060303\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428309\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.017575\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.690182\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00003\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00002:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-12\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: b688b45bc1754c258ba1182c40c39bd8\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-89-96\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.89.96\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1358\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 3.9955923557281494\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 3.9955923557281494\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 3.9955923557281494\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428292\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.077329\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.674819\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00002\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:33,785\tINFO command_runner.py:357 -- Fetched IP: 172.31.89.96\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:33,786\tINFO log_timer.py:25 -- NodeUpdater: ins_ssA3SiZEyR6jLWyvZsbSJahx: Got IP  [LogTimer=1567ms]\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current time: 2022-01-05 16:18:35 (running for 00:00:29.96)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Memory usage on this node: 3.2/62.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Resources requested: 15.0/80 CPUs, 0/0 GPUs, 0.0/216.2 GiB heap, 0.0/92.17 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current best trial: 1d96d_00000 with train-error=0.012302 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0009134032210727258, 'subsample': 0.8722780805626716, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result logdir: /home/ray/ray_results/train_func_model_2022-01-05_16-18-04\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Number of trials: 4/4 (3 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | Trial name                   | status     | loc                 |         eta |   max_depth |   subsample |   iter |   total time (s) |   train-logloss |   train-error |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m |------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------|\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00001 | RUNNING    | 172.31.74.136:1626  | 0.0319993   |           8 |    0.720519 |      3 |         15.679   |        0.615177 |      0.019332 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00002 | RUNNING    | 172.31.89.96:1358   | 0.0264598   |           1 |    0.950598 |      1 |          3.99559 |        0.674819 |      0.077329 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00003 | RUNNING    | 172.31.85.248:1655  | 0.00169914  |           7 |    0.911883 |      2 |         21.7536  |        0.690182 |      0.017575 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00000 | TERMINATED | 172.31.57.130:17733 | 0.000913403 |           7 |    0.872278 |     10 |          3.16501 |        0.685199 |      0.012302 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00002:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-35\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: b688b45bc1754c258ba1182c40c39bd8\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-89-96\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.89.96\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1358\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 26.443671941757202\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 22.448079586029053\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 26.443671941757202\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428315\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.077329\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.657382\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00002\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00001:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-29\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 58b79055036a4e79be3eb96d8352c38b\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-74-136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 4\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.74.136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1626\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 21.78313159942627\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 6.104153871536255\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 21.78313159942627\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428309\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.026362\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.592421\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00001\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00003:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-29\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 7fd2c0791a04419fa78e5ea26dc8b0ef\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-85-248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 3\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.85.248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1655\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 21.761367559432983\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 0.007807016372680664\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 21.761367559432983\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428309\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.024605\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.68871\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00003\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00001:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-35\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 58b79055036a4e79be3eb96d8352c38b\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_tag: 1_eta=0.031999,max_depth=8,subsample=0.72052\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-74-136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.74.136\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1626\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 27.587270975112915\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 0.005905866622924805\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 27.587270975112915\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428315\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.019332\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.478342\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00001\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00003:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-35\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: 7fd2c0791a04419fa78e5ea26dc8b0ef\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_tag: 3_eta=0.0016991,max_depth=7,subsample=0.91188\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-85-248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.85.248\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1655\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 27.574098348617554\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 0.00561213493347168\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 27.574098348617554\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428315\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.010545\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.678362\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00003\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result for train_func_model_1d96d_00002:\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   date: 2022-01-05_16-18-35\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_id: b688b45bc1754c258ba1182c40c39bd8\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   experiment_tag: 2_eta=0.02646,max_depth=1,subsample=0.9506\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   hostname: ip-172-31-89-96\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   iterations_since_restore: 10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   node_ip: 172.31.89.96\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   pid: 1358\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_since_restore: 26.498486280441284\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_this_iter_s: 0.005068063735961914\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   time_total_s: 26.498486280441284\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timestamp: 1641428315\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-error: 0.057996\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   train-logloss: 0.541761\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   training_iteration: 10\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   trial_id: 1d96d_00002\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current time: 2022-01-05 16:18:35 (running for 00:00:30.05)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Memory usage on this node: 3.1/62.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Resources requested: 0/80 CPUs, 0/0 GPUs, 0.0/216.2 GiB heap, 0.0/92.17 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Current best trial: 1d96d_00003 with train-error=0.010545 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0016991434240133134, 'subsample': 0.9118830368337653, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Result logdir: /home/ray/ray_results/train_func_model_2022-01-05_16-18-04\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m Number of trials: 4/4 (4 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | Trial name                   | status     | loc                 |         eta |   max_depth |   subsample |   iter |   total time (s) |   train-logloss |   train-error |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m |------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------|\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00000 | TERMINATED | 172.31.57.130:17733 | 0.000913403 |           7 |    0.872278 |     10 |          3.16501 |        0.685199 |      0.012302 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00001 | TERMINATED | 172.31.74.136:1626  | 0.0319993   |           8 |    0.720519 |     10 |         27.5873  |        0.478342 |      0.019332 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00002 | TERMINATED | 172.31.89.96:1358   | 0.0264598   |           1 |    0.950598 |     10 |         26.4985  |        0.541761 |      0.057996 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m | train_func_model_1d96d_00003 | TERMINATED | 172.31.85.248:1655  | 0.00169914  |           7 |    0.911883 |     10 |         27.5741  |        0.678362 |      0.010545 |\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m +------------------------------+------------+---------------------+-------------+-------------+-------------+--------+------------------+-----------------+---------------+\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1655, ip=172.31.85.248)\u001b[0m 2022-01-05 16:18:35,128\tINFO main.py:1450 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 27.52 seconds (25.36 pure XGBoost training time).\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1358, ip=172.31.89.96)\u001b[0m 2022-01-05 16:18:35,129\tINFO main.py:1450 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 25.74 seconds (23.38 pure XGBoost training time).\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1626, ip=172.31.74.136)\u001b[0m 2022-01-05 16:18:35,113\tINFO main.py:1450 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 27.54 seconds (25.38 pure XGBoost training time).\n",
      "\u001b[2m\u001b[36m(run pid=17661)\u001b[0m 2022-01-05 16:18:35,255\tINFO tune.py:626 -- Total run time: 30.99 seconds (30.04 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# Run tune\n",
    "analysis = tune.run(\n",
    "    train_func_model,\n",
    "    config=config,\n",
    "    metric=\"train-error\",\n",
    "    mode=\"min\",\n",
    "    num_samples=4,\n",
    "    resources_per_trial=ray_params.get_tune_resources()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10ab3eaa-9002-4950-a29e-9790298de949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0016991434240133134, 'subsample': 0.9118830368337653, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters\", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405aff3f-88c9-4c07-b9b1-89dfa6f7a580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss</th>\n",
       "      <th>train-error</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>experiment_tag</th>\n",
       "      <th>config.tree_method</th>\n",
       "      <th>config.objective</th>\n",
       "      <th>config.eval_metric</th>\n",
       "      <th>config.eta</th>\n",
       "      <th>config.subsample</th>\n",
       "      <th>config.max_depth</th>\n",
       "      <th>config.nthread</th>\n",
       "      <th>config.n_jobs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1d96d_00000</th>\n",
       "      <td>0.685199</td>\n",
       "      <td>0.012302</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>f60d9120bf7a414aa308e7a475ac1290</td>\n",
       "      <td>2022-01-05_16-18-10</td>\n",
       "      <td>1641428290</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0_eta=0.0009134,max_depth=7,subsample=0.87228</td>\n",
       "      <td>approx</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.872278</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d96d_00001</th>\n",
       "      <td>0.478342</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>58b79055036a4e79be3eb96d8352c38b</td>\n",
       "      <td>2022-01-05_16-18-35</td>\n",
       "      <td>1641428315</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1_eta=0.031999,max_depth=8,subsample=0.72052</td>\n",
       "      <td>approx</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0.031999</td>\n",
       "      <td>0.720519</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d96d_00002</th>\n",
       "      <td>0.541761</td>\n",
       "      <td>0.057996</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>b688b45bc1754c258ba1182c40c39bd8</td>\n",
       "      <td>2022-01-05_16-18-35</td>\n",
       "      <td>1641428315</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2_eta=0.02646,max_depth=1,subsample=0.9506</td>\n",
       "      <td>approx</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>0.950598</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d96d_00003</th>\n",
       "      <td>0.678362</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>7fd2c0791a04419fa78e5ea26dc8b0ef</td>\n",
       "      <td>2022-01-05_16-18-35</td>\n",
       "      <td>1641428315</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3_eta=0.0016991,max_depth=7,subsample=0.91188</td>\n",
       "      <td>approx</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.911883</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             train-logloss  train-error  time_this_iter_s  done  \\\n",
       "trial_id                                                          \n",
       "1d96d_00000       0.685199     0.012302          0.004223  True   \n",
       "1d96d_00001       0.478342     0.019332          0.005906  True   \n",
       "1d96d_00002       0.541761     0.057996          0.005068  True   \n",
       "1d96d_00003       0.678362     0.010545          0.005612  True   \n",
       "\n",
       "            timesteps_total episodes_total  training_iteration  \\\n",
       "trial_id                                                         \n",
       "1d96d_00000            None           None                  10   \n",
       "1d96d_00001            None           None                  10   \n",
       "1d96d_00002            None           None                  10   \n",
       "1d96d_00003            None           None                  10   \n",
       "\n",
       "                                experiment_id                 date  \\\n",
       "trial_id                                                             \n",
       "1d96d_00000  f60d9120bf7a414aa308e7a475ac1290  2022-01-05_16-18-10   \n",
       "1d96d_00001  58b79055036a4e79be3eb96d8352c38b  2022-01-05_16-18-35   \n",
       "1d96d_00002  b688b45bc1754c258ba1182c40c39bd8  2022-01-05_16-18-35   \n",
       "1d96d_00003  7fd2c0791a04419fa78e5ea26dc8b0ef  2022-01-05_16-18-35   \n",
       "\n",
       "              timestamp  ...  iterations_since_restore  \\\n",
       "trial_id                 ...                             \n",
       "1d96d_00000  1641428290  ...                        10   \n",
       "1d96d_00001  1641428315  ...                        10   \n",
       "1d96d_00002  1641428315  ...                        10   \n",
       "1d96d_00003  1641428315  ...                        10   \n",
       "\n",
       "                                            experiment_tag config.tree_method  \\\n",
       "trial_id                                                                        \n",
       "1d96d_00000  0_eta=0.0009134,max_depth=7,subsample=0.87228             approx   \n",
       "1d96d_00001   1_eta=0.031999,max_depth=8,subsample=0.72052             approx   \n",
       "1d96d_00002     2_eta=0.02646,max_depth=1,subsample=0.9506             approx   \n",
       "1d96d_00003  3_eta=0.0016991,max_depth=7,subsample=0.91188             approx   \n",
       "\n",
       "            config.objective  config.eval_metric  config.eta  \\\n",
       "trial_id                                                       \n",
       "1d96d_00000  binary:logistic    [logloss, error]    0.000913   \n",
       "1d96d_00001  binary:logistic    [logloss, error]    0.031999   \n",
       "1d96d_00002  binary:logistic    [logloss, error]    0.026460   \n",
       "1d96d_00003  binary:logistic    [logloss, error]    0.001699   \n",
       "\n",
       "             config.subsample config.max_depth config.nthread config.n_jobs  \n",
       "trial_id                                                                     \n",
       "1d96d_00000          0.872278                7              1             1  \n",
       "1d96d_00001          0.720519                8              1             1  \n",
       "1d96d_00002          0.950598                1              1             1  \n",
       "1d96d_00003          0.911883                7              1             1  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26be7928-b380-4135-a988-9e72dfaeda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7f8e5-bf4c-436f-95b1-8609aecf170f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1886c8e-70ba-4776-94cd-a12916732f67",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    " * [Ray Train: Tune: Scalable Hyperparameter Tuning](https://docs.ray.io/en/master/tune/index.html)\n",
    " * [Introducing Distributed XGBoost Training with Ray](https://www.anyscale.com/blog/distributed-xgboost-training-with-ray)\n",
    " * [How to Speed Up XGBoost Model Training](https://www.anyscale.com/blog/how-to-speed-up-xgboost-model-training)\n",
    " * [XGBoost-Ray Project](https://github.com/ray-project/xgboost_ray)\n",
    " * [Distributed XGBoost on Ray](https://docs.ray.io/en/latest/xgboost-ray.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
