{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214ce2a5-6b11-41d9-86f4-a2b4f0d1a6d9",
   "metadata": {},
   "source": [
    "### Example of Model Composition\n",
    "\n",
    "<img src=\"images/PatternsMLProduction.png\" width=\"70%\" height=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80759c48-1b18-4ea6-8aa1-6ddbb9083207",
   "metadata": {},
   "source": [
    "#### Install HuggingFace Transformers and Torch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d229a03-ce6e-4ae8-8857-adcfdc402daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "Collecting torch\n",
      "  Using cached torch-1.11.0-cp38-none-macosx_10_9_x86_64.whl (129.9 MB)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp38-cp38-macosx_10_11_x86_64.whl (3.6 MB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m820.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.4.24-cp38-cp38-macosx_10_9_x86_64.whl (289 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.1/289.1 KB\u001b[0m \u001b[31m411.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from sacremoses->transformers) (8.1.2)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Installing collected packages: tokenizers, tqdm, torch, regex, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.5.1 regex-2022.4.24 sacremoses-0.0.49 tokenizers-0.12.1 torch-1.11.0 tqdm-4.64.0 transformers-4.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23d1ccb-6951-4e22-aafd-48c74c4635de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TranslationPipeline, TextClassificationPipeline\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from ray import serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a709b04e-cc7d-4869-8a9f-919d20a2b4cd",
   "metadata": {},
   "source": [
    "Example tweetes. These could come live from a Tweeter\n",
    "handle using Twitter APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "873b8bfd-1ee3-4d9c-bea4-e66924747ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS = [\"Tonight on my walk, I got mad because mom wouldn't let me play with this dog. We stared at each other...he never blinked!\",\n",
    "          \"Sometimes. when i am bored. i will stare at nothing. and try to convince the human. that there is a ghost\",\n",
    "          \"You little dog shit, you peed and pooed on my new carpet. Bad dog!\",\n",
    "          \"I would completely believe you. Dogs and little children - very innocent and open to seeing such things\",\n",
    "          \"You've got too much time on your paws. Go check on the skittle. under the, fridge\",\n",
    "          \"You sneaky little devil, I can't live without you!!!\",\n",
    "          \"It's true what they say about dogs: they are you BEST BUDDY, no matter what!\",\n",
    "          \"This dog is way dope, just can't enough of her\",\n",
    "          \"This dog is way cool, just can't enough of her\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e6e502-0e23-470d-84f3-fbfdf80f4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fetch a tweet; this could very well be live \n",
    "# tweets coming from Twitter API for a user or #hashtag\n",
    "def fetch_tweet_text(i):\n",
    "    text = TWEETS[i]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50cf772-0fa6-4eaf-8288-b1cb5836f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyse the tweet using a pretrained Transformer\n",
    "# from HuggingFace\n",
    "@serve.deployment(num_replicas=1)\n",
    "def sentiment_model(text: str):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, task=\"sentiment-analysis\")\n",
    "\n",
    "    return pipeline(text)[0]['label'], pipeline(text)[0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a813a1c8-c577-4028-ad09-8b4dea439e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate a tweet from English --> French \n",
    "# using a pretrained Transformer from HuggingFace\n",
    "@serve.deployment(num_replicas=2)\n",
    "def translate_model(text: str):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "    model = AutoModelWithLMHead.from_pretrained(\"t5-small\")\n",
    "    use_gpu = 0 if torch.cuda.is_available() else -1\n",
    "    pipeline = TranslationPipeline(model, tokenizer, task=\"translation_en_to_fr\", device=use_gpu)\n",
    "\n",
    "    return pipeline(text)[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08cec76c-3ef5-4741-914b-edb2c4fd2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A composed class is deployed with both sentiment analysis and translations models'\n",
    "# Serve Handles initialized in the constructor\n",
    "@serve.deployment(route_prefix=\"/composed\", num_replicas=2)\n",
    "class ComposedModel:\n",
    "    def __init__(self):\n",
    "        # fetch and initialize deployment handles\n",
    "        self.translate_model = translate_model.get_handle(sync=False)\n",
    "        self.sentiment_model = sentiment_model.get_handle(sync=False)\n",
    "\n",
    "    async def __call__(self, starlette_request):\n",
    "        data = starlette_request.query_params['data']\n",
    "\n",
    "        sentiment, score = await(await self.sentiment_model.remote(data))\n",
    "        trans_text = await(await self.translate_model.remote(data))\n",
    "\n",
    "        return {'Sentiment': sentiment, 'score': score, 'Translated Text': trans_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc61315-27e0-4b1b-a4aa-ae6abd2faa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 16:12:50,963\tINFO services.py:1456 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(ServeController pid=61718)\u001b[0m 2022-04-26 16:12:53,596\tINFO checkpoint_path.py:15 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(ServeController pid=61718)\u001b[0m 2022-04-26 16:12:53,704\tINFO http_state.py:106 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:WJOxXp:SERVE_PROXY_ACTOR-node:127.0.0.1-0' on node 'node:127.0.0.1-0' listening on '127.0.0.1:8000'\n",
      "2022-04-26 16:12:54,550\tINFO api.py:794 -- Started Serve instance in namespace 'serve'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x7fd2da3cce50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=61720)\u001b[0m INFO:     Started server process [61720]\n"
     ]
    }
   ],
   "source": [
    "serve.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b39401d3-8fb0-410c-bb61-d25164fbeab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 16:13:06,178\tINFO api.py:615 -- Updating deployment 'sentiment_model'. component=serve deployment=sentiment_model\n",
      "\u001b[2m\u001b[36m(ServeController pid=61718)\u001b[0m 2022-04-26 16:13:06,198\tINFO deployment_state.py:1210 -- Adding 1 replicas to deployment 'sentiment_model'. component=serve deployment=sentiment_model\n",
      "2022-04-26 16:13:09,194\tINFO api.py:630 -- Deployment 'sentiment_model' is ready at `http://127.0.0.1:8000/sentiment_model`. component=serve deployment=sentiment_model\n",
      "2022-04-26 16:13:09,204\tINFO api.py:615 -- Updating deployment 'translate_model'. component=serve deployment=translate_model\n",
      "\u001b[2m\u001b[36m(ServeController pid=61718)\u001b[0m 2022-04-26 16:13:09,308\tINFO deployment_state.py:1210 -- Adding 2 replicas to deployment 'translate_model'. component=serve deployment=translate_model\n",
      "2022-04-26 16:13:12,220\tINFO api.py:630 -- Deployment 'translate_model' is ready at `http://127.0.0.1:8000/translate_model`. component=serve deployment=translate_model\n",
      "2022-04-26 16:13:12,228\tINFO api.py:615 -- Updating deployment 'ComposedModel'. component=serve deployment=ComposedModel\n",
      "\u001b[2m\u001b[36m(ServeController pid=61718)\u001b[0m 2022-04-26 16:13:12,302\tINFO deployment_state.py:1210 -- Adding 2 replicas to deployment 'ComposedModel'. component=serve deployment=ComposedModel\n",
      "2022-04-26 16:13:15,243\tINFO api.py:630 -- Deployment 'ComposedModel' is ready at `http://127.0.0.1:8000/composed`. component=serve deployment=ComposedModel\n"
     ]
    }
   ],
   "source": [
    "sentiment_model.deploy()\n",
    "translate_model.deploy()\n",
    "ComposedModel.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e72dd6-df3b-4236-bd78-d4b0b9bec98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending tweet request... : Tonight on my walk, I got mad because mom wouldn't let me play with this dog. We stared at each other...he never blinked!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(translate_model pid=61724)\u001b[0m /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:907: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "\u001b[2m\u001b[36m(translate_model pid=61724)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 'POSITIVE', 'score': 0.965121328830719, 'Translated Text': \"Ce soir, j'ai été fou parce que ma mère ne me laisse pas jouer avec ce chien.\"}\n",
      "Sending tweet request... : Sometimes. when i am bored. i will stare at nothing. and try to convince the human. that there is a ghost\n",
      "{'Sentiment': 'NEGATIVE', 'score': 0.99788898229599, 'Translated Text': \"Parfois. quand j'ennuie. je ne regarderai rien. et essayerai de convaincre l'homme.\"}\n",
      "Sending tweet request... : You little dog shit, you peed and pooed on my new carpet. Bad dog!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(translate_model pid=61725)\u001b[0m /usr/local/anaconda3/envs/ray-core-tutorial/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:907: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "\u001b[2m\u001b[36m(translate_model pid=61725)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 'NEGATIVE', 'score': 0.9984055161476135, 'Translated Text': \"Je n'ai pas eu l'impression d'avoir eu l'impression d'avoir eu l'impression d'avoir eu l'impression d'avoir eu l'impression d'avoir eu l'impression d'avoir eu l'impression d'avoir eu l'impression d'avoir eu l'impression d'avoir eu l'impression\"}\n",
      "Sending tweet request... : I would completely believe you. Dogs and little children - very innocent and open to seeing such things\n",
      "{'Sentiment': 'POSITIVE', 'score': 0.9997748732566833, 'Translated Text': 'Je vous croyais tout à fait: chiens et petits enfants - très innocents et ouverts à ce genre de choses'}\n",
      "Sending tweet request... : You've got too much time on your paws. Go check on the skittle. under the, fridge\n",
      "{'Sentiment': 'NEGATIVE', 'score': 0.9995866417884827, 'Translated Text': 'Vous avez trop de temps sur vos pattes.'}\n",
      "Sending tweet request... : You sneaky little devil, I can't live without you!!!\n",
      "{'Sentiment': 'POSITIVE', 'score': 0.9949393272399902, 'Translated Text': 'Du petit diable, je ne peux pas vivre sans vous !!!'}\n",
      "Sending tweet request... : It's true what they say about dogs: they are you BEST BUDDY, no matter what!\n",
      "{'Sentiment': 'POSITIVE', 'score': 0.9996572732925415, 'Translated Text': \"C'est vrai ce qu'ils disent sur les chiens : ils sont tu MEILLEUR BUDDY, peu importe quoi!\"}\n",
      "Sending tweet request... : This dog is way dope, just can't enough of her\n",
      "{'Sentiment': 'NEGATIVE', 'score': 0.9972212314605713, 'Translated Text': 'Ce chien est assez dope, il ne peut pas assez de lui'}\n",
      "Sending tweet request... : This dog is way cool, just can't enough of her\n",
      "{'Sentiment': 'POSITIVE', 'score': 0.9847627282142639, 'Translated Text': 'Ce chien est bien cool, il ne peut pas assez de lui'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(TWEETS)):\n",
    "    tweet = fetch_tweet_text(i)\n",
    "    print(F\"Sending tweet request... : {tweet}\")\n",
    "    resp = requests.get(\"http://127.0.0.1:8000/composed\", params={'data': tweet})\n",
    "    print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786fcf2e-1afa-4900-bc3f-0fc8844d5b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeController pid=61718)\u001b[0m 2022-04-26 16:19:06,268\tINFO deployment_state.py:1236 -- Removing 1 replicas from deployment 'sentiment_model'. component=serve deployment=sentiment_model\n",
      "\u001b[2m\u001b[36m(ServeController pid=61718)\u001b[0m 2022-04-26 16:19:06,272\tINFO deployment_state.py:1236 -- Removing 2 replicas from deployment 'translate_model'. component=serve deployment=translate_model\n",
      "\u001b[2m\u001b[36m(ServeController pid=61718)\u001b[0m 2022-04-26 16:19:06,276\tINFO deployment_state.py:1236 -- Removing 2 replicas from deployment 'ComposedModel'. component=serve deployment=ComposedModel\n"
     ]
    }
   ],
   "source": [
    "serve.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
