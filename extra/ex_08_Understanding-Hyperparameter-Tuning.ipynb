{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Tune - A gentle introduction understanding hyperparameters optimization\n",
    "\n",
    "¬© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "üìñ [Back to Table of Contents](../ex_00_tutorial_overview.ipynb)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lesson introduces the concepts of _Hyperparameter Tuning or Optimization_ (HPO) and works through a nontrivial example using Tune. \n",
    "\n",
    "\n",
    "### Learning Objective:\n",
    "In this introductory tutorial, you will:\n",
    " * understand the Ray tune concepts, components and architecture\n",
    " * how to use its API to tune distributed hyper-parameter optimzation\n",
    " * walk through a short example\n",
    "\n",
    "See also the [Hyperparameter Tuning References](References-Hyperparameter-Tuning.ipynb) notebook and the [Tune documentation](http://tune.io), in particular, the [API reference](https://docs.ray.io/en/latest/tune/api_docs/overview.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are Hyperparameters?\n",
    "\n",
    "In _supervised learning_, we train a model with labeled data so the model can properly label new data values. Everything about the model is defined by a set of _parameters_, such as the weights in a linear regression. \n",
    "\n",
    "In contrast, the _hyperparameters_<sup>1</sup> define structural details about the kind of model itself, like whether or not we are using a linear regression or what architecture is best for a neural network, etc. Other quantities considered hyperparameters include learning rates, discount rates, etc. If we want our training process and resulting model to work well, we first need to determine the optimal or near-optimal set of hyperparameters.\n",
    "\n",
    "How do we determine the optimal hyperparameters? The most straightfoward approach is to perform a loop where we pick a candidate set of values from some reasonably inclusive list of possible values, train a model, compare the results achieved with previous loop iterations, and pick the set that performed best. This process is called _Hyperparameter Tuning_ or _Optimization_ (HPO).\n",
    "\n",
    "This simple algorithm can quickly become very expensive, however. Training a single neural networks can be compute intensive and the space of all possible architectures is huge. Hence, much of the research in hyperparameter tuning, especially for neural networks, focuses on ways to optimize HPO, such as early stopping and pruning the search space when some combinations appear to perform poorly.\n",
    "\n",
    "1. _Hyperparameter_ is often spelled _hyper parameter_ or _hyper-parameter_, but we'll use the spelling with no space or dash.\n",
    "\n",
    "<img src=\"images/what-are-hyperparameters.png\" height=\"25%\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Example: $k$-Means \n",
    "\n",
    "Let's start with a very simple example of HPO, finding $k$ in $k$-means. \n",
    "\n",
    "The $k$-means algorithm finds clusters in a data set. It's a canonical example of _unsupervised learning_, where information is extracted from a data set, rather than using labeled data to train a model for labelling new data, as in _supervised learning_. We won't discuss the algorithm details, but the essense of it involves a \"guess\" for the expected number of clusters, the $k$ value, then calculating $k$ centroids (the coordinates at the center), one per cluster, along with determining to which cluster each data point belongs. The details are in [$k$-means Wikipedia article](https://en.wikipedia.org/wiki/K-means_clustering). The following animation shows the algorithm in action for a two-dimensional data set where three clusters are evident.\n",
    "\n",
    "#### K-Means Convergence\n",
    "\n",
    "<img src=\"images/K-means_convergence.gif\">\n",
    "\n",
    "(source: [Wikipedia](https://en.wikipedia.org/wiki/K-means_clustering). [Larger Image](https://en.wikipedia.org/wiki/K-means_clustering#/media/File:K-means_convergence.gif))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is easy to see the clusters in this two-dimensional data set, that won't be for arbitrary datasets, especially those with more than three dimensions. Hence, we should determine the best $k$ value by trying many values and picking the value that appears to be best. In this case, \"best\" would mean that we minimize the distances between the datapoints and centroids. \n",
    "\n",
    "With just one hyperparameter, this problem is comparatively simple and brute force calculations to find the optimal $k$ is usually good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO for Neural Networks\n",
    "\n",
    "Where HPO really becomes a challenge is finding the right neural network architecture for your problem. Why are neural networks a challenge? Consider this image of a typical architecture:\n",
    "\n",
    "<img src=\"images/hpo-neural-network-example.png\" height=\"25%\" width=\"60%\">\n",
    "\n",
    "Every number you see is a hyperparameter! So are the decisions about how many layers to have, what kind of layer to use for each layer, etc. The space of possible hyperparameters is enormous, too big to explore naively.\n",
    "\n",
    "So called _neural architecture search_ (NAS) has become a research field in its own right, along with general research in optimizing HPO. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Ray Tune\n",
    "\n",
    "[Ray Tune](http://tune.io) is the Ray-based native library for hyperparameter tuning. Tune makes it nearly as easy to run distributed, parallelized HPO as it is to run trials on a single machine manually, one after the other. \n",
    "\n",
    "Tune is built as an extensible, pluggable framework, with built-in integrations for many frameworks, [PyTorch](https://pytorch.org), [TensorFlow](http://tensorflow.org), and recently, [sci-kit learn](https://scikit-learn.org/stable/) (see [this recent blog post](https://medium.com/distributed-computing-with-ray/gridsearchcv-2-0-new-and-improved-ee56644cbabf)).\n",
    "\n",
    "## How Tune Works\n",
    "\n",
    "Before we get into using Tune, let's understand the some definitions, terms, and components. With this understanding, you will get an insight into what happens when you use Tune to search your hyperparameter space and optimize your process to select the best, optimized model.\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/tune_flow.png\" height=\"25%\" width=\"60%\">\n",
    "\n",
    "## Definitions\n",
    "\n",
    "Let's get an intuition of what those terms mean.  \n",
    "\n",
    "#### Trainable\n",
    "This is your training function, with an objective function. As [trainable](https://docs.ray.io/en/latest/tune/api_docs/trainable.html?highlight=trainable#ray.tune.Trainable), it's one of the argument to `tune.run(...)` method. Tune offers two iterface APIs for trainable: functional and class.\n",
    "\n",
    "#### Search Spaces\n",
    "To optimize your hyperparameters, you have to define a search space. A search space defines valid values for your hyperparameters and can specify how these values are sampled (e.g., from a uniform distribution or a normal distribution).\n",
    "\n",
    "#### Search Algorithms\n",
    "To optimize the hyperparameters of your training process, you use a Search Algorithm which suggests hyperparameter configurations. If you don‚Äôt specify a search algorithm, Tune will use random search by default, which can provide you with a good starting point for your hyperparameter optimization.\n",
    "\n",
    "#### Schedulers\n",
    "To make your training process more efficient, you can use a Trial Scheduler. For instance, in our trainable example minimizing a function in a training loop, we used tune.report(). This reported incremental results, given a hyperparameter configuration selected by a search algorithm. Based on these reported results, a Tune scheduler can decide whether to stop the trial early or not. If you don‚Äôt specify a scheduler, Tune will use a first-in-first-out (FIFO) scheduler by default, which simply passes through the trials selected by your search algorithm in the order they were picked and does not perform any early stopping.\n",
    "\n",
    "In short, schedulers can stop, pause, or tweak the hyperparameters of running trials, potentially making your hyperparameter tuning process much faster. Unlike search algorithms, Trial Scheduler do not select which hyperparameter configurations to evaluate.\n",
    "\n",
    "#### Trial\n",
    "\n",
    "A trial is an execution or run of a logical representation of a single hyperparameter configuration. Each trial is associated with an instance of a Trainable. And a collection of trials comprise an experiment.\n",
    "\n",
    "\n",
    "#### Lifecycle of a trial¬∂\n",
    "A trial‚Äôs life cycle consists of 6 stages:\n",
    "\n",
    "Initialization (generation): A trial is first generated as a hyperparameter sample, and its parameters are configured according to what was provided in `tune.run` as part of the `config` arggument. Trials are then placed into a queue to be executed (with status PENDING).\n",
    "\n",
    "**PENDING**: A pending trial is a trial to be executed on the machine. Every trial is configured with resource values. Whenever the trial‚Äôs resource values are available, tune will run the trial (by starting a ray actor holding the config and the training function).\n",
    "\n",
    "**RUNNING**: A running trial is assigned a Ray Actor. There can be multiple running trials in parallel.\n",
    "\n",
    "**ERRORED**: If a running trial throws an exception, Tune will catch that exception and mark the trial as errored. Note that exceptions can be propagated from an actor to the main Tune driver process. If `max_retries` is set, Tune will set the trial back into ‚ÄúPENDING‚Äù and later start it from the last checkpoint.\n",
    "\n",
    "**TERMINATED**: A trial is terminated if it is stopped or finished by a Stopper/Scheduler. If using the Function API, the trial is also terminated when the function stops.\n",
    "\n",
    "**PAUSED**: A trial can be paused by a Trial scheduler. This means that the trial‚Äôs actor will be stopped too. A paused trial can later be resumed from the most recent checkpoint.\n",
    "\n",
    "\n",
    "#### Driver/worker process\n",
    "\n",
    "The driver process is the python process that calls `tune.run` (which calls ray.init() underneath the hood); therefore, you\n",
    "do not need to invoke `ray.init(...)` explicity. Tune does it for you during its inital run. The Tune's driver process runs on the node where you run your script (which calls `tune.run`), while Ray Tune trainable ‚Äúactors‚Äù run on any node (either on the same node on multiple cores) or on worker nodes (with multiple cores on a distributed Ray cluster).\n",
    "\n",
    "#### Ray Actors\n",
    "\n",
    "Tune uses Ray Actors as worker node's processes to evaluate multiple Trainables in parallel.\n",
    "\n",
    "[Ray Actors](https://docs.ray.io/en/latest/actors.html#actor-guide) allow you to parallelize an instance of a class in Python. When you instantiate a class that is a Ray actor, Ray will start a instance of that class on a separate process either on the same machine (or another distributed machine, if running a Ray cluster). This actor can then asynchronously execute method calls and maintain its own internal state.\n",
    "\n",
    "### The execution of a trainable¬∂\n",
    "Tune uses Ray actors to parallelize the evaluation of multiple hyperparameter configurations. Each actor is a Python process that executes an instance of the user-provided Trainable. The definition of the user-provided Trainable will be [serialized via cloudpickle](https://docs.ray.io/en/latest/serialization.html#serialization-guide) and sent to each actor process. Each Ray actor will start an instance of the Trainable to be executed.\n",
    "\n",
    "If the Trainable is a class, it will be executed iteratively by calling train/step. After each invocation, the driver is notified that a ‚Äúresult dict‚Äù is ready. The driver will then pull the result via `ray.get`.\n",
    "\n",
    "If the trainable is a callable or a function, it will be executed on the Ray actor process on a separate execution thread. Whenever `tune.report` is called, the execution thread is paused and waits for the driver to pull a result. After pulling, the actor‚Äôs execution thread will automatically resume.\n",
    "\n",
    "The diagram below depicts how Tune launches trainables on the worker nodes as processes in which the the trainables are run. \n",
    "Each trial will have its own instance of a trainable, hence we parallelize trials and its respective configuration across cores on a worker. \n",
    "\n",
    "<img src=\"images/ray_tune_report_launch_trainables.png\" height=\"25%\" width=\"60%\">\n",
    "\n",
    "Whenever the trainble calls `tune.report`, the driver will pull the metrics via `ray.get`, as shown in the diagram below.\n",
    "\n",
    "<img src=\"images/ray_tune_report_metrics.png\" height=\"25%\" width=\"60%\">\n",
    "\n",
    "\n",
    "Tune also integrates implementations of many state-of-the-art [search algorithms](https://docs.ray.io/en/latest/tune/key-concepts.html#search-algorithms) and [schedulers](https://docs.ray.io/en/latest/tune/key-concepts.html#schedulers), so it is easy to optimize your HPO process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three simple steps to use Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8273\" target=\"_blank\">http://127.0.0.1:8273</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8273', python_version='3.8.13', ray_version='3.0.0.dev0', ray_commit='{{RAY_COMMIT_SHA}}', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-07-29_10-28-04_101382_2959/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-07-29_10-28-04_101382_2959/sockets/raylet', 'webui_url': '127.0.0.1:8273', 'session_dir': '/tmp/ray/session_2022-07-29_10-28-04_101382_2959', 'metrics_export_port': 62473, 'gcs_address': '127.0.0.1:64181', 'address': '127.0.0.1:64181', 'dashboard_agent_listen_port': 52365, 'node_id': '81876f3c6e34015f2a526c2ceefcbcf5cf73387962dd73394059f5b1'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ray.init(logging_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup training using Trainable APIs\n",
    "\n",
    "Let's define our objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_fn(step, width, height):\n",
    "    time.sleep(0.1)\n",
    "    return (0.1 + width * step / 100)**(-1) + height * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a Trainable used by Tune using Tune's [Functional API](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#function-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_objective_fn(config):\n",
    "    # fetch our Hyperparameters sent as arguments\n",
    "    width, height = config[\"width\"], config[\"height\"]\n",
    "    # Iterate over number of steps\n",
    "    for step in range(config[\"steps\"]):\n",
    "        # Iterative training function - can be any arbitrary training procedure\n",
    "        # Here our objective function is the evaluation_fn\n",
    "        intermediate_score = evaluation_fn(step, width, height)\n",
    "        # Feed the score back back to Tune.\n",
    "        tune.report(iterations=step, mean_loss=intermediate_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Use tune API to execute tuning\n",
    "\n",
    "This will do a grid search over the activation parameter. This means that each of the two values (`relu` and `tanh`) will be sampled once for each sample (`num_samples`). We end up with `2 * N = 2N samples`, where is N is `num_samples`. The width and height parameters are sampled randomly. `steps` is a constant parameter.\n",
    "\n",
    "The `tune.run(...)` API returns a large [analysis](https://docs.ray.io/en/latest/tune/api_docs/analysis.html#analysis-tune-analysis) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-18 09:06:31 (running for 00:00:03.14)<br>Memory usage on this node: 20.1/64.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/10 CPUs, 0/0 GPUs, 0.0/39.32 GiB heap, 0.0/2.0 GiB objects<br>Current best trial: 9436d_00003 with mean_loss=-5.425669254265192 and parameters={'steps': 5, 'width': 4.576539242686842, 'height': -89.58469559984677, 'activation': 'tanh'}<br>Result logdir: /Users/jules/ray_results/easy_objective_fn_2022-07-18_09-06-27<br>Number of trials: 10/10 (10 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    easy_objective_fn,\n",
    "    metric=\"mean_loss\",\n",
    "    mode=\"min\",\n",
    "    num_samples=5,\n",
    "    # Define our hypyerparameter search space\n",
    "    config={\n",
    "        \"steps\": 5,\n",
    "        \"width\": tune.uniform(0, 20),\n",
    "        \"height\": tune.uniform(-100, 100),\n",
    "        \"activation\": tune.grid_search([\"relu\", \"tanh\"]),\n",
    "    },\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Analyse the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'steps': 5, 'width': 4.576539242686842, 'height': -89.58469559984677, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>mean_loss</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>neg_mean_loss</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>experiment_tag</th>\n",
       "      <th>config.steps</th>\n",
       "      <th>config.width</th>\n",
       "      <th>config.height</th>\n",
       "      <th>config.activation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9436d_00000</th>\n",
       "      <td>4</td>\n",
       "      <td>3.329998</td>\n",
       "      <td>0.113018</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.329998</td>\n",
       "      <td>a1813e135a554922b674ac1e8a0be4b9</td>\n",
       "      <td>2022-07-18_09-06-30</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>0.557857</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0_activation=relu,height=20.4609,width=16.9717</td>\n",
       "      <td>5</td>\n",
       "      <td>16.971743</td>\n",
       "      <td>20.460862</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436d_00001</th>\n",
       "      <td>4</td>\n",
       "      <td>4.620703</td>\n",
       "      <td>0.105743</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.620703</td>\n",
       "      <td>6c78ab82390740c198ec087eb0a932aa</td>\n",
       "      <td>2022-07-18_09-06-31</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>0.523544</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>1_activation=tanh,height=21.4085,width=7.5812</td>\n",
       "      <td>5</td>\n",
       "      <td>7.581245</td>\n",
       "      <td>21.408504</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436d_00002</th>\n",
       "      <td>4</td>\n",
       "      <td>5.093847</td>\n",
       "      <td>0.106594</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.093847</td>\n",
       "      <td>86804ab54c54414297ff23614cf6edfd</td>\n",
       "      <td>2022-07-18_09-06-31</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>0.523724</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>2_activation=relu,height=34.3086,width=12.5332</td>\n",
       "      <td>5</td>\n",
       "      <td>12.533160</td>\n",
       "      <td>34.308568</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436d_00003</th>\n",
       "      <td>4</td>\n",
       "      <td>-5.425669</td>\n",
       "      <td>0.104017</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>5.425669</td>\n",
       "      <td>7e028e93a65940bfb758a807ee537d2f</td>\n",
       "      <td>2022-07-18_09-06-31</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>0.523478</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>3_activation=tanh,height=-89.5847,width=4.5765</td>\n",
       "      <td>5</td>\n",
       "      <td>4.576539</td>\n",
       "      <td>-89.584696</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436d_00004</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.822946</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>1.822946</td>\n",
       "      <td>1329f94462754285a89533df93b99b90</td>\n",
       "      <td>2022-07-18_09-06-31</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>0.532685</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>4_activation=relu,height=-35.5489,width=11.9347</td>\n",
       "      <td>5</td>\n",
       "      <td>11.934685</td>\n",
       "      <td>-35.548858</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             iterations  mean_loss  time_this_iter_s  done timesteps_total  \\\n",
       "trial_id                                                                     \n",
       "9436d_00000           4   3.329998          0.113018  True            None   \n",
       "9436d_00001           4   4.620703          0.105743  True            None   \n",
       "9436d_00002           4   5.093847          0.106594  True            None   \n",
       "9436d_00003           4  -5.425669          0.104017  True            None   \n",
       "9436d_00004           4  -1.822946          0.107686  True            None   \n",
       "\n",
       "            episodes_total  training_iteration  neg_mean_loss  \\\n",
       "trial_id                                                        \n",
       "9436d_00000           None                   5      -3.329998   \n",
       "9436d_00001           None                   5      -4.620703   \n",
       "9436d_00002           None                   5      -5.093847   \n",
       "9436d_00003           None                   5       5.425669   \n",
       "9436d_00004           None                   5       1.822946   \n",
       "\n",
       "                                experiment_id                 date  ...  \\\n",
       "trial_id                                                            ...   \n",
       "9436d_00000  a1813e135a554922b674ac1e8a0be4b9  2022-07-18_09-06-30  ...   \n",
       "9436d_00001  6c78ab82390740c198ec087eb0a932aa  2022-07-18_09-06-31  ...   \n",
       "9436d_00002  86804ab54c54414297ff23614cf6edfd  2022-07-18_09-06-31  ...   \n",
       "9436d_00003  7e028e93a65940bfb758a807ee537d2f  2022-07-18_09-06-31  ...   \n",
       "9436d_00004  1329f94462754285a89533df93b99b90  2022-07-18_09-06-31  ...   \n",
       "\n",
       "               node_ip  time_since_restore  timesteps_since_restore  \\\n",
       "trial_id                                                              \n",
       "9436d_00000  127.0.0.1            0.557857                        0   \n",
       "9436d_00001  127.0.0.1            0.523544                        0   \n",
       "9436d_00002  127.0.0.1            0.523724                        0   \n",
       "9436d_00003  127.0.0.1            0.523478                        0   \n",
       "9436d_00004  127.0.0.1            0.532685                        0   \n",
       "\n",
       "            iterations_since_restore warmup_time  \\\n",
       "trial_id                                           \n",
       "9436d_00000                        5    0.001975   \n",
       "9436d_00001                        5    0.002242   \n",
       "9436d_00002                        5    0.001622   \n",
       "9436d_00003                        5    0.003478   \n",
       "9436d_00004                        5    0.001862   \n",
       "\n",
       "                                              experiment_tag  config.steps  \\\n",
       "trial_id                                                                     \n",
       "9436d_00000   0_activation=relu,height=20.4609,width=16.9717             5   \n",
       "9436d_00001    1_activation=tanh,height=21.4085,width=7.5812             5   \n",
       "9436d_00002   2_activation=relu,height=34.3086,width=12.5332             5   \n",
       "9436d_00003   3_activation=tanh,height=-89.5847,width=4.5765             5   \n",
       "9436d_00004  4_activation=relu,height=-35.5489,width=11.9347             5   \n",
       "\n",
       "             config.width  config.height config.activation  \n",
       "trial_id                                                    \n",
       "9436d_00000     16.971743      20.460862              relu  \n",
       "9436d_00001      7.581245      21.408504              tanh  \n",
       "9436d_00002     12.533160      34.308568              relu  \n",
       "9436d_00003      4.576539     -89.584696              tanh  \n",
       "9436d_00004     11.934685     -35.548858              relu  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.results_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Tune's TuneGridSearchCV and Scikit-Learn\n",
    "Basically, there are three basic steps or Ray Tune pattern for you as a newcomer to get started with using Ray Tune. We'll use a drop-in replacement for normal Scikit-learn's distributed `TuneGridSearchCV` \n",
    "\n",
    "See also the [Tune documentation](http://tune.io/), in particular, the [API reference](https://docs.ray.io/en/latest/tune/api_docs/overview.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tune's replacement\n",
    "from ray.tune.sklearn import TuneGridSearchCV\n",
    "\n",
    "# Other relevant imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use the stochastic gradient descent (SGD) classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# import the classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Set\n",
    " * 250K rows\n",
    " * 250 features\n",
    " * 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_data() -> (np.ndarray, np.ndarray):\n",
    "    X, y = make_classification(\n",
    "        n_samples=250000,\n",
    "        n_features=250,\n",
    "        n_informative=50,\n",
    "        n_redundant=0,\n",
    "        n_classes=2,\n",
    "        class_sep=2.5)\n",
    "    return X, y\n",
    "\n",
    "X, y = create_classification_data()\n",
    "# Split the dataset into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Define parameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters grid to tune from SGDClassifier\n",
    "parameter_grid = {\"alpha\": [1e-4, 1e-1, 1], \"epsilon\": [0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Use Ray's Scikit-learn drop-in replacement TuneGridSearchCV\n",
    "\n",
    "Use all cores on a Ray Cluster (or local host) to tune\n",
    "\n",
    "The `early_stopping parameter` allows us to terminate unpromising configurations. If `early_stopping=True`, `TuneGridSearchCV` will default to using Tune‚Äôs `ASHAScheduler`. You can pass in a custom algorithm - see Tune‚Äôs documentation on schedulers here for a full list to choose from. \n",
    "\n",
    "`max_iters` is the maximum number of iterations a given hyperparameter set could run for; it may run for fewer iterations if it is early stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do with Tune's in-place replacement\n",
    "# Note: If early_stopping=True, TuneGridSearchCV will default to using Tune‚Äôs ASHAScheduler.\n",
    "tune_sklearn = TuneGridSearchCV(SGDClassifier(), \n",
    "                    parameter_grid,\n",
    "                    early_stopping=True,\n",
    "                    max_iters=30,\n",
    "                    n_jobs=-1,    # Use all cores if running on a cluster\n",
    "                    mode=\"min\",\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Run tune\n",
    "\n",
    "The `.fit()` under the hood will call tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-18 09:13:52 (running for 00:00:25.32)<br>Memory usage on this node: 21.2/64.0 GiB<br>Using AsyncHyperBand: num_stopped=5\n",
       "Bracket: Iter 16.000: -0.9693083333333334 | Iter 4.000: -0.96451875 | Iter 1.000: -0.966909375<br>Resources requested: 0/10 CPUs, 0/0 GPUs, 0.0/39.32 GiB heap, 0.0/2.0 GiB objects<br>Current best trial: 8e695_00003 with average_test_score=0.9653750000000001 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.PARTIAL_FIT: 1>, 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': <function _passthrough_scorer at 0x139288160>}, 'max_iters': 30, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'alpha': 0.0001, 'epsilon': 0.1}<br>Result logdir: /Users/jules/ray_results/_Trainable_2022-07-18_09-13-27<br>Number of trials: 6/6 (6 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TuneGridSearchCV(early_stopping=True, estimator=SGDClassifier(), max_iters=30,\n",
       "                 mode=&#x27;min&#x27;, n_jobs=-1,\n",
       "                 param_grid={&#x27;alpha&#x27;: [0.0001, 0.1, 1], &#x27;epsilon&#x27;: [0.01, 0.1]},\n",
       "                 sk_n_jobs=1, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TuneGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>TuneGridSearchCV(early_stopping=True, estimator=SGDClassifier(), max_iters=30,\n",
       "                 mode=&#x27;min&#x27;, n_jobs=-1,\n",
       "                 param_grid={&#x27;alpha&#x27;: [0.0001, 0.1, 1], &#x27;epsilon&#x27;: [0.01, 0.1]},\n",
       "                 sk_n_jobs=1, verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "TuneGridSearchCV(early_stopping=True, estimator=SGDClassifier(), max_iters=30,\n",
       "                 mode='min', n_jobs=-1,\n",
       "                 param_grid={'alpha': [0.0001, 0.1, 1], 'epsilon': [0.01, 0.1]},\n",
       "                 sk_n_jobs=1, verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_sklearn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Tune Scikit-learn TuneGridSearchCV Best params: {'alpha': 0.1, 'epsilon': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ray Tune Scikit-learn TuneGridSearchCV Best params: {tune_sklearn.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "1. Walk through and convert into a notebook the quick PyTorch Tutorial with Ray Tune\n",
    "2. Try some Ray Tune [How-to guides](https://docs.ray.io/en/latest/tune/examples/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
